---
title: "Open & Synthetic Data"
output:
  html_notebook:
    toc: yes
    toc_float: true
    toc_collapsed: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

# Packages
Here, we load the packages that we will use for data wrangling, as well as the `synthpop` package, which we will use to generate synthetic data.
```{r}
library(tidyverse) # data wrangling
library(synthpop) # install.packages('synthpop')
library(ggeasy) # install.packages('ggeasy')
```

# Data Synthesis {.tabset}
## 01 - Swallowing
These data were reported in "Normative Reference Values for FEES and VASES: Preliminary Data From 39 Nondysphagic, Community-Dwelling Adults" by Curtis et al. (2023) (https://doi.org/10.1044/2023_JSLHR-23-00132) and were retrieved from https://osf.io/4anzm/.

### Loading Data
```{r}
#Load data
swallowing_data <-
  read.csv(here::here("Data/01_Swallowing/norms_ratings.csv")) |>
  # clean variable names
  janitor::clean_names() |>
  # select only relevant variables
  dplyr::select(c(study_id, bolus_consistency, laryngeal_vestibule_severity_rating)) |> 
  mutate(
    # create binary variable for 'absent' when 0 and present when > 0
    lv_zero = if_else(laryngeal_vestibule_severity_rating == 0, "Absent", "Present"),
    # create variables for 'amount of residue when present'
    lv_present = ifelse(
      laryngeal_vestibule_severity_rating > 0,
      laryngeal_vestibule_severity_rating,
      NA
    )
  )

# Visualize distribution
break_trans = scales::trans_new('clip_range',
                                \(x) ifelse(x <= 50, x, x - 350),
                                \(x) ifelse(x <= 50, x, x + 350))

ggplot(swallowing_data,
       aes(x = laryngeal_vestibule_severity_rating, fill = lv_zero, color = lv_zero)) +
  geom_histogram(bins = 105) +
  coord_trans(y = break_trans) +
  cowplot::theme_cowplot() +
  scale_x_continuous(limits = c(-1, 100),
                     breaks = seq(from = 0, to = 100, by = 5.0)) +
  scale_y_continuous(
    limits = c(-1, 450),
    breaks = c(
      0,
      10,
      20,
      30,
      40,
      50,
      405,
      425,
      450
    )
  ) +
  geom_hline(yintercept = 50,
             linetype = "solid",
             color = "dark grey") +
  scale_fill_manual(values = c("orange", "blue")) +
  scale_color_manual(values = c("white", "white")) +
  labs(x = "Laryngeal Vestibule Residue Rating (%)",
       y = "Count") +
  ggeasy::easy_remove_legend()

# Summarise distribution
## Percentage of 'present' laryngeal vestibule residue
### Thin (IDDSI 1)
swallowing_data |> 
  filter(bolus_consistency == "Thin (IDDSI 0)") |> 
  count(lv_zero) |> 
  mutate(total = sum(n)) |> 
  mutate(perc = (n/total)*100)

### Pudding & Cracker
swallowing_data |> 
  filter(bolus_consistency != "Thin (IDDSI 0)") |> 
  count(lv_zero) |> 
  mutate(total = sum(n)) |> 
  mutate(perc = (n/total)*100)

## Median and IQR for 'present' laryngeal vestibule residue
swallowing_data |> 
  filter(bolus_consistency == "Thin (IDDSI 0)" & lv_zero == "Present") |> 
  summarise(median = median(lv_present),
            IQR_high = quantile(lv_present, 0.75),
            IQR_low = quantile(lv_present, 0.25))
```

### Generating Synthetic Data

### Comparisons

## 02 - Articulation
These data were reported in "Vowel Acoustics as Predictors of Speech Intelligibility in Dysarthria" by Thompson et al. (2023)
(https://doi.org/10.1044/2022_JSLHR-22-00287) and were retrieved from: https://osf.io/hr7aj/.

### Loading Data
```{r}
data_articulation <- rio::import(
  file = "Data/02_Articulation/data_Acoustic Measures.csv"
) |>
  
  # Remove the reliability trials that have "_rel" in the SpeakerID variable
  dplyr::filter(
    !grepl(
      pattern = "_rel",
      x = SpeakerID
  ))
```

### Generating Synthetic Data

### Comparisons

## 03 - Fluency

## 04 - Voice/Resonance
These data were reported in "Hypernasality associated with basal ganglia dysfunction: Evidence from Parkinson's disease and Huntington's disease" by Novotny et al. (2016) (https://doi.org/10.7717/peerj.2530) and were retrieved from https://peerj.com/articles/2530/#supp-1.

### Loading Data
```{r}
# Load data
voice_data <-
  readxl::read_excel(here::here("Data/04_Voice_Resonance/RawData.xlsx"), range = "B3:Z114") |>
  # clean variable names
  janitor::clean_names() |>
  # select only relevant variables
  dplyr::select(c(names, efn_sd_d_b, median_of_raters))

# Examine correlation between overall perceptual rating and acoustic EFn SD parameter
cor.test(voice_data$median_of_raters, voice_data$efn_sd_d_b, method = "pearson")
```

## 05 - Hearing
These data were reported in "Ubiquitous enhancement of spatial hearing in congenitally blind people" by Battal et al. (2020) (https://doi.org/10.31234/osf.io/veh7t) and were retrieved from https://osf.io/tav35/.

### Loading Data
```{r}
# Load packages
library(nlme) # LMM

# Load data
plane.thre.out <- read.table(here::here("Data/05_Hearing/All_Thresholds_outliersmarked-500B.txt"), sep=",", header=T)

# Convert variables to factors
names(plane.thre.out)[4]<-c('head')
plane.thre.out$arm <- factor(plane.thre.out$arm)
plane.thre.out$subj <- factor(plane.thre.out$subj)
plane.thre.out$head <- factor(plane.thre.out$head)
plane.thre.out$planes <- factor(plane.thre.out$planes)
plane.thre.out$group <- ifelse(plane.thre.out$group=='EB', c('CB'), c('SC'))
plane.thre.out$group <-factor(plane.thre.out$group)

#omit all +-3SD outliers 
plane.thre.out<- subset(plane.thre.out, outlier==0)
plane.thre.out[which(plane.thre.out$thre >12),]

#divide back
horizontal.thre.out <- subset(plane.thre.out,planes=='hor')
vertical.thre.out <- subset(plane.thre.out,planes=='ver')

rownames(horizontal.thre.out) <-c(1:nrow(horizontal.thre.out)) #correct the row numbers
horizontal.thre.out[which(horizontal.thre.out$thre >10),] # we know from glmm there's one outlier
horizontal.thre.out <-horizontal.thre.out[-c(188),] 

rownames(vertical.thre.out) <-c(1:nrow(vertical.thre.out))
vertical.thre.out[which(vertical.thre.out$thre >12),] # we know from glmm there's one outlier
vertical.thre.out <-vertical.thre.out[-c(144),] 

# in the horizontal back condition left arm is right area // right arm is left area of the subject
hor.thre.front <- subset(horizontal.thre.out, head ==1)
hor.thre.back <- subset(horizontal.thre.out, head ==2)

hor.thre.back$arm <-as.character(hor.thre.back$arm)
hor.thre.back <- within(hor.thre.back, arm[arm=="left"] <-("Alien"))#just to assign into a temp
hor.thre.back <- within(hor.thre.back, arm[arm=='right'] <- 'left')
hor.thre.back <- within(hor.thre.back, arm[arm=='Alien'] <- 'right')

horizontal.thre.out <-rbind(hor.thre.front,hor.thre.back)

# combine them back
plane.thre.out <- rbind(horizontal.thre.out,vertical.thre.out)
plane.thre.out$arm <- factor(plane.thre.out$arm)
plane.thre.out$subj <- factor(plane.thre.out$subj)
plane.thre.out$head <- factor(plane.thre.out$head)
plane.thre.out$planes <- factor(plane.thre.out$planes)
plane.thre.out$group <-factor(plane.thre.out$group)

#divide back
horizontal.thre.out <- subset(plane.thre.out,planes=='hor')
vertical.thre.out <- subset(plane.thre.out,planes=='ver')

# LMM on planes: Auditory localization performance by plane, group and position (head)
# this is the model itself - subject is the random fx
plane.out.nlme <- lme(thre ~ 1 + planes * group * head, random = ~ 1|subj, weights = varIdent(form = ~ 1 | planes), data = plane.thre.out)

# Results
my.plane.anova <- anova(plane.out.nlme)
my.plane.anova
```

## 06 - AAC

## 07 - Language
These data were reported in "Relationships between reading performance and regional spontaneous brain activity following surgical removal of primary left-hemisphere tumors: A resting-state fMRI study" by Kearney et al. (2023) (https://doi.org/10.1016/j.neuropsychologia.2023.108631) and were retrieved from https://osf.io/3abxs.

### Loading Data
```{r}
# Load data
language_data <-
  read.csv(here::here("Data/07_Language/demographics_CAT_reading.csv")) |>
  # select only relevant variables
  dplyr::select(c(Filename, edu, tpost_cat_read_total))

# Examine correlation between education (years) and reading t-scores
cor.test(language_data$edu, language_data$tpost_cat_read_total, method = "spearman")
```

## 08 - Cognition
These data were reported in "Emotion recognition of faces and emoji in individuals with moderate-severe traumatic brain injury" by Clough et al. (2023) (https://doi.org/10.1080/02699052.2023.2181401 and were retrieved from https://osf.io/enjd8/.

### Loading Data
```{r}
# Load packages
library(lme4) # glmer
library(lmerTest)
library(broom.mixed)

# Load data
cognition_data <-
  read.csv(here::here("Data/08_Cognition/emoji_affect_recognition_data.csv")) |>
  # select only relevant variables
  dplyr::select(c(SubjectID, Correct, Group, Condition, Sex)) |>
  # dummy-code Group (NC = 1, TBI = 0) and Sex (F = 1, M = 0)
  mutate(
    Group_NC = if_else(Group == "NC", 1, 0),
    Sex_F = if_else(Sex == "Female", 1, 0)) |>
  # treat categorical variables as factors and set reference levels
  mutate(
    SubjectID = as.factor(SubjectID),
    Correct = as.factor(Correct),
    Group_NC = relevel(as.factor(Group_NC), '1', '0'),
    Condition = relevel(as.factor(Condition), 'BasicFace', 'BasicEmoji', 'SocialEmoji'),
    Sex_F =  relevel(as.factor(Sex_F), '1', '0')
  )

# Set up Helmert contrast coding for Condition
# https://marissabarlaz.github.io/portfolio/contrastcoding/
# Contrast 1: Basic Emotion Faces vs average of Basic Emotion Emoji and Social Emotion Emoji
# Contrast 2: Basic Emotion Emoji vs Social Emotion Emoji
helmert = matrix(c(2/3, -1/3, -1/3, 0, 1/2, -1/2), ncol = 2)
contrasts(cognition_data$Condition) = helmert

# Models: Effect of stimulus condition on emotion recognition accuracy
# Note: Model first failed to converge when using default control settings, so changed optimizer to bobyqa as suggested here: https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
m1 <- lme4::glmer(Correct ~ Group_NC + Condition + Sex_F + Group_NC*Condition*Sex_F + (1 |SubjectID), data = cognition_data, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",
                            optCtrl=list(maxfun=2e5)))
summary(m1)

# Set group reference level to TBI (0) and rerun model
cognition_data$Group_NC = relevel(cognition_data$Group_NC, '0', '1')
m2 <- lme4::glmer(Correct ~ Group_NC + Condition + Sex_F + Group_NC*Condition*Sex_F + (1 |SubjectID), data = cognition_data, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",
                            optCtrl=list(maxfun=2e5)))
summary(m2)

# Odds ratios and confidence intervals
tidy(m1,conf.int=TRUE,exponentiate=TRUE,effects="fixed") # Condition1 conf.high = 5.86, reported in paper as 5.87
tidy(m2,conf.int=TRUE,exponentiate=TRUE,effects="fixed")
```

## 09 - Social Communication
These data were reported in "Difficulties with pronouns in autism: Experimental results from Thai children with autism" by Chanchaochai & Schwarz (2023) (https://doi.org/10.1080/10489223.2023.2262457) and were retrieved from https://osf.io/92jgd/.
### Loading Data
```{r}
# Load data
Comp <-
  read.csv(here::here("Data/09_Social_Communication/Study1Comp.csv"),
           fileEncoding = 'UTF-8-BOM')

subjdata <-
  plyr::ddply(
    Comp,
    c("ParGroup", "Subj", "Gender"),
    summarise,
    N    = length(Accuracy),
    acc  = sum(Accuracy),
    pct = mean(Accuracy),
    grade = mean(Grade),
    age = mean(Months),
    NVIQ = mean(SSIQ)
  )

# Model: Non-verbal IQ by group (ASD, TD)
summary(aov(NVIQ ~ ParGroup, subjdata))
```

## {- .leave-tabset}